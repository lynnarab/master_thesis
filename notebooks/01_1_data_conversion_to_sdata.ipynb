{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b53df353-1293-4c63-b9ce-023976205536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/lyarab/micromamba/envs/spatialdata-fixed/lib/python3.11/site-packages/dask/dataframe/__init__.py:31: FutureWarning: The legacy Dask DataFrame implementation is deprecated and will be removed in a future version. Set the configuration option `dataframe.query-planning` to `True` or None to enable the new Dask Dataframe implementation and silence this warning.\n",
      "  warnings.warn(\n",
      "/scratch/lyarab/micromamba/envs/spatialdata-fixed/lib/python3.11/site-packages/anndata/utils.py:434: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import spatialdata as sd\n",
    "import spatialdata_plot\n",
    "from spatialdata_io import xenium, codex\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import sopa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff7886c-b3c3-421c-a0af-442fe584f5ca",
   "metadata": {},
   "source": [
    "## Convert raw data into .zarr format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc242aa9-f9ba-4eba-bcd5-ce40cf7a0972",
   "metadata": {},
   "source": [
    "### Xenium data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fad08b-2165-46e5-a571-f090247af75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define source and destination directories\n",
    "xenium_path_read = Path('/scratch/lyarab/Xenium/Run3')  # Folder containing Xenium datasets\n",
    "xenium_path_write = Path('../data/SpatialData/Xenium')  # Destination folder for .zarr files\n",
    "\n",
    "# Ensure the destination folder exists\n",
    "xenium_path_write.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Iterate over each folder in xenium_path_read\n",
    "for folder in xenium_path_read.iterdir():\n",
    "    if folder.is_dir():  # Ensure it's a directory\n",
    "        input_path = str(folder)\n",
    "        output_path = str(xenium_path_write / f\"{folder.name}.zarr\")\n",
    "\n",
    "        print(f\"Processing: {folder.name}\")\n",
    "\n",
    "        # Parse the data\n",
    "        print(\"Parsing the data... \", end=\"\")\n",
    "        sdata = xenium(\n",
    "            path=input_path,\n",
    "            n_jobs=1,  \n",
    "            cells_boundaries=True,  \n",
    "            nucleus_boundaries=True,\n",
    "            morphology_focus=True,\n",
    "            cells_as_circles=True,\n",
    "        )\n",
    "        print(\"done\")\n",
    "\n",
    "        # Write the data\n",
    "        print(\"Writing the data... \", end=\"\")\n",
    "        sdata.write(output_path, overwrite = True)\n",
    "        print(\"done\")\n",
    "\n",
    "print(\"All files processed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e2d4e-3c51-4c52-a476-e590023678d9",
   "metadata": {},
   "source": [
    "### CODEX data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b585ea-8876-40b6-abcc-44e8b356f741",
   "metadata": {},
   "source": [
    "#### Slide by slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31813d4c-5384-4de8-8ead-e246d49b730f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36;20m[INFO] (sopa.io.reader.phenocycler)\u001b[0m Found channel names ['DAPI' 'FoxP3' 'aSMA' 'CD4' 'CD8' 'CD31' 'CD11c' 'IFNG' 'Pan-Cytokeratin'\n",
      " 'CD68' 'CD20' 'CD66b' 'TNFa' 'CD45RO' 'CD14' 'CD11b' 'Vimentin' 'CD163'\n",
      " 'IL10' 'CD45' 'CCR7' 'CD38' 'CD69' 'Podoplanin' 'PNAd' 'CD16' 'CXCL13']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ID_0022111_Scan1.er.qptiff\n",
      "Parsing the data... done\n",
      "Writing the data... \u001b[34mINFO    \u001b[0m The Zarr backing store has been changed from \u001b[3;35mNone\u001b[0m the new file path:                                      \n",
      "         ..\u001b[35m/data/SpatialData/CODEX/\u001b[0m\u001b[95mID_0022111_Scan1.er.zarr\u001b[0m                                                        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36;20m[INFO] (sopa.io.reader.phenocycler)\u001b[0m Found channel names ['DAPI' 'FoxP3' 'aSMA' 'CD4' 'CD8' 'CD31' 'CD11c' 'IFNG' 'Pan-Cytokeratin'\n",
      " 'CD68' 'CD20' 'CD66b' 'TNFa' 'CD45RO' 'CD14' 'CD11b' 'Vimentin' 'CD163'\n",
      " 'IL10' 'CD45' 'CCR7' 'CD38' 'CD69' 'Podoplanin' 'PNAd' 'CD16' 'CXCL13']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Processing: ID_0022110_Scan1.er.qptiff\n",
      "Parsing the data... done\n",
      "Writing the data... \u001b[34mINFO    \u001b[0m The Zarr backing store has been changed from \u001b[3;35mNone\u001b[0m the new file path:                                      \n",
      "         ..\u001b[35m/data/SpatialData/CODEX/\u001b[0m\u001b[95mID_0022110_Scan1.er.zarr\u001b[0m                                                        \n",
      "done\n",
      "All files processed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define source and destination directories\n",
    "codex_path_read = Path('/scratch/lyarab/CODEX/')  # Folder containing CODEX datasets\n",
    "codex_path_write = Path('../data/SpatialData/CODEX/')  # Destination folder for .zarr files\n",
    "\n",
    "# Ensure the destination folder exists\n",
    "codex_path_write.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Iterate over each folder in codex_path_read\n",
    "for file in codex_path_read.iterdir():\n",
    "    if file.is_file() and not file.name.startswith(\"._\"):  # Ignore hidden/system files\n",
    "        input_path = str(file)  \n",
    "        output_path = str(codex_path_write / f\"{file.stem}.zarr\")  # Use filename without extension\n",
    "\n",
    "        print(f\"Processing: {file.name}\")\n",
    "\n",
    "        try:\n",
    "            # Parse the data\n",
    "            print(\"Parsing the data... \", end=\"\")\n",
    "            sdata = sopa.io.phenocycler(path=input_path)\n",
    "            print(\"done\")\n",
    "\n",
    "            # Write the data\n",
    "            print(\"Writing the data... \", end=\"\")\n",
    "            sdata.write(output_path)\n",
    "            print(\"done\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {file.name} due to error: {e}\")\n",
    "\n",
    "print(\"All files processed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d45650-1932-43de-b768-c69ecfa88ddd",
   "metadata": {},
   "source": [
    "#### Column by column: From ome.tif to zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37526a2-816d-4da4-9ebe-9fa68d3e36cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define source and destination directories\n",
    "codex_path_read = Path('/scratch/lyarab/CODEX_cropped/')  # Folder containing CODEX datasets\n",
    "codex_path_write = Path('../data/SpatialData/CODEX_cropped/')  # Destination folder for .zarr files\n",
    "\n",
    "# Ensure the destination folder exists\n",
    "codex_path_write.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Iterate over each folder in codex_path_read\n",
    "for file in codex_path_read.iterdir():\n",
    "    if file.is_file() and not file.name.startswith(\"._\"):  # Ignore hidden/system files\n",
    "        input_path = str(file)  \n",
    "        output_path = str(codex_path_write / f\"{file.stem}.zarr\")  # Use filename without extension\n",
    "\n",
    "        print(f\"Processing: {file.name}\")\n",
    "\n",
    "        try:\n",
    "            # Parse the data\n",
    "            print(\"Parsing the data... \", end=\"\")\n",
    "            sdata = sopa.io.ome_tif(path=input_path)\n",
    "            print(\"done\")\n",
    "\n",
    "            # Write the data\n",
    "            print(\"Writing the data... \", end=\"\")\n",
    "            sdata.write(output_path)\n",
    "            print(\"done\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {file.name} due to error: {e}\")\n",
    "\n",
    "print(\"All files processed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatialdata-fixed",
   "language": "python",
   "name": "spatialdata-fixed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
